<!DOCTYPE html>
<html>

<head>
    <title>脉冲神经网络知识体系</title>
    <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdui@1.0.1/dist/css/mdui.min.css"
        integrity="sha384-cLRrMq39HOZdvE0j6yBojO4+1PrHfB7a9l5qLcmRm/fiWXYY+CndJPmyu5FV/9Tw" crossorigin="anonymous" />
    <link href="https://cdn.bootcdn.net/ajax/libs/highlight.js/11.7.0/styles/github.min.css" rel="stylesheet">
</head>

<body>
    <div class="mdui-theme-primary-light-green mdui-theme-accent-lime">
        <div class="mdui-toolbar mdui-color-theme">
            <a href="/" class="mdui-btn mdui-btn-icon" mdui-tooltip="{content: '主页'}">
                <i class="mdui-icon material-icons">home</i>
            </a>
            <a href="javascript:void(0);" class="mdui-typo-title">脉冲神经网络知识体系</a>
            <div class="mdui-toolbar-spacer"></div>
            <a href="javascript:comingSoon();" class="mdui-btn mdui-btn-icon" mdui-tooltip="{content: '搜索'}">
                <i class="mdui-icon material-icons">search</i>
            </a>
            <a href="javascript:comingSoon();" class="mdui-btn mdui-btn-icon" mdui-tooltip="{content: '刷新'}">
                <i class="mdui-icon material-icons">refresh</i>
            </a>
            <a href="javascript:comingSoon();" class="mdui-btn mdui-btn-icon" mdui-tooltip="{content: '更多'}">
                <i class="mdui-icon material-icons">more_vert</i>
            </a>
        </div>
    </div>

    <div class="banner" style="position: relative; width: 100%; height: 30vh;">
        <img src="./assets/1-1.png" style="position: absolute; width: 100%; height: 100%; object-fit: cover;">
        <div class="cover" style="position: absolute; width: 100%; height: 100%; background-color: rgba(0, 0, 0, 0.2);">
        </div>
    </div>

    <div class="mdui-container" style="padding: 2rem 0;">
        <div id="content" class="mdui-typo">
            <h1 id="_1">脉冲神经网络知识体系</h1>
<h2 id="1">1 脉冲神经网络的编码机制</h2>
<p>不同于模拟神经网络（ANN）的是，脉冲神经网络（SNN）中的值以脉冲的形式传递。将数值转为脉冲的过程被称作编码（encoding）。在脉冲神经网络中，根据信息编码为脉冲时所利用到的属性的不同，可以将编码机制分为以下几种：</p>
<h3 id="11">1.1 速率编码</h3>
<p>速率编码设想神经元的放电（即脉冲）频率隐含信息，因此以脉冲放电频率作为编码的基础。脉冲放电的频率越高，其所代表的值越大。$^{[1][2]}$</p>
<p>$$
\begin{matrix}
→ & t \\\\
| & & | & | & | & & & | & 5 \\\\
| & & & | & & & & & 2 \\\\
| & | & | & | & | & | & | & | & 8 \\\\
| & & & | & | & & | & & 4
\end{matrix}
$$</p>
<p>速率编码可用python模拟如下所示：</p>
<pre><code class="language-python">import torch
import random

def rate_coding(values, precision: int = 20):
    while True:
        yield torch.tensor([(v &gt;= random.randint(0, precision)) + 0.0 for v in values])

values = [5, 2, 8, 4]
prec = 40
rc = rate_coding(values, prec)

sum = torch.zeros(len(values))

for i in range(prec):
    spikes = next(rc)
    print(spikes)
    sum += spikes

print(sum)
</code></pre>
<p>速率编码的优势在于：</p>
<ol>
<li>
<p>鲁棒性更强：速率编码不受脉冲时序的影响，因此对于输入信号的微小变化更加鲁棒。在时间编码中，输入信号的微小变化可能会导致脉冲时序的变化，从而影响神经元的激活。</p>
</li>
<li>
<p>更高的信息传输速率：由于速率编码使用脉冲的频率来表示输入信号的大小，因此可以使用更高的频率来传输更多的信息。相比之下，时间编码的信息传输速率较低，因为每个脉冲都需要一定的时间来传输。</p>
</li>
<li>
<p>更容易实现：速率编码只需要统计一段时间内脉冲的数量，因此更容易实现。相比之下，时间编码需要准确地测量脉冲的时间，这可能需要更高的精度和计算能力。</p>
</li>
</ol>
<p>然而，其也存在劣势：</p>
<ol>
<li>
<p>时间/空间开销较大：在速率编码中，每个神经元需要记录一定时间内脉冲的数量，因此需要较大的存储空间和计算成本，信息也只能在时间窗口的末尾才能表现出来。相比之下，时间编码中只需要记录每个脉冲的相对时间，且由于首个脉冲携带信息的可能性更大，因此空间开销较小。</p>
</li>
<li>
<p>精度有限：速率编码的精度受到采样时间的限制，采样时间越短，精度越高，但同时也会增加计算复杂度和存储需求。相比之下，时间编码可以获得更高的精度，因为它可以记录每个脉冲的确切时间。</p>
</li>
<li>
<p>不易处理异步事件：在速率编码中，每个神经元的脉冲频率是连续的，因此难以处理异步事件。相比之下，时间编码可以处理不同神经元之间的异步事件，因为每个脉冲的相对时间是离散的。</p>
</li>
</ol>
<h3 id="12">1.2 时间编码</h3>
<p>时间编码设想脉冲间精确的放电时间隐含信息，因此以脉冲之间放电的精确时间作为编码的基础。一般是以最早到达神经元的脉冲作为基准，相对放电时间越晚，所代表的值越大。$^{[1][3]}$</p>
<p>$$
\begin{matrix}
→ & t \\\\
 & & | & | & | & & & | & 2 \\\\
| & & & | & & & & & 0 \\\\
 & | & | & | & | & | & | & | & 1 \\\\
 & & & & & | & | & & 5
\end{matrix}
$$</p>
<p>时间编码可用python模拟如下所示：</p>
<pre><code class="language-python">import torch
import random

def temporal_coding(values):
    t = 0
    while True:
        yield torch.tensor([min(1, (v == t) + min((v &lt;= t), random.randint(0, 1))) + 0.0 for v in values])
        t += 1

values = [2, 0, 1, 5]
time_steps = 40
rc = temporal_coding(values)

for i in range(time_steps):
    spikes = next(rc)
    print(spikes)
</code></pre>
<p>时间编码的优势在于：</p>
<ol>
<li>
<p>更高的精度：时间编码可以记录每个脉冲的精确时间，因此相比于速率编码，时间编码可以获得更高的精度。</p>
</li>
<li>
<p>更高的信息容量：时间编码可以通过微小的时间差来编码不同的输入信号，因此可以获得更高的信息容量。这对于需要处理大量输入信号的任务非常有用。</p>
</li>
<li>
<p>更适用于异步事件：采用时间编码时，不同神经元之间的事件不需要同步。这对于需要处理异步事件的任务非常有用。</p>
</li>
</ol>
<p>然而，时间编码的劣势也很明显：</p>
<ol>
<li>鲁棒性不足：时间编码中时间所代表的值取决于每个脉冲与最早产生的脉冲之间的相对时间差，当最早产生的脉冲易主时，整个脉冲所包含的时间会随之变化。</li>
</ol>
<h2 id="2">2 脉冲神经网络神经元的类型</h2>
<p>与模拟神经网络相似的是，脉冲神经网络的组成也是由神经元组成层，再由层组成整个脉冲神经网络计算网络。脉冲神经网络中神经元的选择也尤为关键。神经元的目的是处理输入的脉冲，并且由输入的脉冲产生对应输出的脉冲。根据内部运算方式的不同，神经元模型可以被分为如下几种。其中由于脉冲神经网络中神经元的生物学原理相似，每种神经元之间都能找到相对应的共有的结构或模式，但每种神经元彼此之间又不尽相同。</p>
<p>在以下第2章和第3章对神经元模型及训练的描述中，规定以下符号：</p>
<p>（1）使用$O_{i}^{l}(t)$表示位于第$l$层的第$i$个神经元在第$t$个时间刻的脉冲输出；</p>
<p>（2）使用$U_{i}^{l}(t)$表示位于第$l$层的第$i$个神经元在第$t$个时间刻的神经元电位值；</p>
<p>（3）使用$X_{i}^{l}(t)$表示位于第$l$层的第$i$个神经元在第$t$个时间刻的模拟输出；</p>
<p>（4）使用$H_{i}^{l}(t)$表示位于第$l$层的第$i$个神经元在第$t$个时间刻的历史遗留电位。</p>
<h3 id="21-hh">2.1 霍奇金-赫胥黎神经元模型（HH模型）</h3>
<p>HH模型将细胞膜看作一个具有膜电容$C_{M}$和泄露电导$G_{M}$的模型，由于细胞膜内外离子浓度的不同，细胞膜会维持在一个静息电位$V_{rest}$。离子$K^{+}$和$Na^{+}$的流动也会对膜电位产生一定影响。可将其总结为如下公式：$^{[4]}$</p>
<p>$$I_{m}=C_{m}\frac{dV_{m}}{dt}+I_{Na}+I_{K}+I_{l}$$</p>
<p>其中泄露电流的计算公式可以总结如下</p>
<p>$$I_{l}=g_{l}(V-E_{L})$$</p>
<p>钠离子电流的计算公式可以总结如下</p>
<p>$$I_{Na}=g_{Na}(V-E_{Na})$$</p>
<p>钾离子电流的计算公式可以总结如下</p>
<p>$$I_{K}=g_{K}(V-E_{K})$$</p>
<p>整个模型如下图所示：</p>
<p><img alt="霍奇金-赫胥黎模型示意图" src="./assets/1-1.png" /></p>
<h3 id="22-leaky-integrate-and-firelif">2.2 Leaky Integrate and Fire（LIF）模型</h3>
<p>由HH模型我们得知，注入细胞的电流满足如下公式：</p>
<p>$$I=C\frac{dV}{dt}+g_{Na}(V-E_{Na})+g_{K}(V-E_{K})+g_{L}(V-E_{L})$$</p>
<p>将电流整合在一起，可以得到：</p>
<p>$$I=g(V-E)+C\frac{dV}{dt}$$</p>
<p>其中</p>
<p>$$g=g_{Na}+g_{K}+g_{L},E=\frac{E_{Na}+E_{K}+E_{L}}{g_{Na}+g_{K}+g_{L}}$$</p>
<p>设初值$t=t_{0},V=V_{0}$，解微分方程可得</p>
<p>$$V=(V_{0}-E-\frac{I}{g})e^{-\frac{t-t_{0}}{\tau }}+E+\frac{I}{g}$$</p>
<p>其中$\tau =\frac{C}{g}$为时间常数，约等于$10ms$。</p>
<p>上式表明，在持续稳定的电流作用下，神经元的电位会逐渐达到顶峰；当受到短暂的电流刺激后，神经元的电位有时来不及达到顶峰便直接开始衰减。此时膜电位的值就和输入脉冲的个数、频率等有关。加入微小时间分量$\Delta t$，当自然衰减时，可以得到</p>
<p>$$V(t)=\frac{I}{g}[1-(1-\frac{\Delta t}{\tau })]e^{-\frac{t-t_{0}-\Delta t}{\tau }}+E=\frac{I}{g}\frac{\Delta t}{\tau }e^{-\frac{t-t_{0}}{\tau }}+E$$</p>
<p>又由$q=I\Delta t$，$C=g\tau $得</p>
<p>$$V(t)=\frac{q}{C}e^{-\frac{t-t_{0}}{\tau }}+E$$</p>
<p>这便是LIF模型的生物学原理：在受到刺激时，神经元胞体内会产生反应，造成胞体电位的上升；胞体电位会随时间而衰减，会随新脉冲的到来而增加；当电位越过阈值时，神经元电位重置，并产生一段时间的不应期（期间不产生任何脉冲）。</p>
<p>整个LIF模型使用数学公式描述如下：$^{[5]}$</p>
<p>（1）神经元胞体电位，由突触传来的脉冲、偏置电位与历史电位相加而成，</p>
<p>$$U_{i}^{l}(t)=\sum_{j}{w_{ij}O_{j}^{l-1}(t)}+b_{i}+H_{i}^{l}(t)$$</p>
<p>其中$w_{ij}$为权重，$b_{i}$为偏置；</p>
<p>（2）神经元是否产生脉冲，由电位与阈值经过Heaviside阶跃函数$u(·)$得出，</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>其中$u_{th}$为阈电位；</p>
<p>（3）神经元历史电位，由当前电位与是否产生脉冲得出，</p>
<p>$$H_{i}^{l}(t)=\tau U_{i}^{l}(t-1)[1-O_{i}^{l}(t-1)]$$</p>
<p>其中$\tau $为时间常数。</p>
<p><img alt="LIF神经元计算示意图" src="./assets/1-2.png" /></p>
<p>整个模型可用python模拟如下：</p>
<pre><code class="language-python">import torch

class Heaviside(torch.autograd.Function): 
    @staticmethod
    def forward(ctx, i):
        ctx.save_for_backward(i)
        return i.gt(0).float()

    @staticmethod
    def backward(ctx, g_o):
        i = ctx.saved_tensors
        g_i = g_o.clone() 
        temp = abs(i) &lt; 0.5
        return g_i * temp.float(), None

class LIF(torch.nn.Module):
    def __init__(self, input_shape: int, output_shape: int, max_weight: float, bias: float, threshold: float, tau: float, weights: torch.tensor = None):
        super().__init__()
        self.input_shape = input_shape
        self.output_shape = output_shape
        self.max_weight = max_weight
        self.bias = bias
        self.threshold = threshold
        self.tau = tau
        if weights is None:
            self.weights = torch.rand(self.output_shape, self.input_shape) * max_weight
        else:
            self.weights = weights
        self.history = torch.zeros(self.output_shape)

    def forward(self, x):
        x = x.view(self.input_shape, 1)
        x = self.weights @ x
        x = x.view(self.output_shape)
        x = x + self.bias + self.history
        o = Heaviside.apply(x - self.threshold)
        self.history = (x * self.tau) * (1 - o)
        return o

if __name__ == &quot;__main__&quot;:
    values = [5, 2, 8, 4, 0, 3]
    prec = 40
    rc = rate_coding(values, prec)
    lif = LIF(6, 4, 8, 0, 12, 0.5)

    for i in range(prec):
        input_spikes = next(rc)
        output_spikes = lif(input_spikes)
        print(output_spikes)
</code></pre>
<h3 id="23-spike-response-model-0srm0">2.3 Spike Response Model 0（SRM0）</h3>
<p>LIF模型的电位在神经元的胞体中累积并计算脉冲，而SRM0模型的电位在各个突触中累积并计算脉冲。在SRM0模型中，来自前一个神经元的脉冲在突触处累积电位，在胞体中加和并计算脉冲。</p>
<p>整个SRM0模型使用公式描述如下：$^{[6]}$</p>
<p>（1）各个突触内的电位，由上一层的脉冲与该突触的历史相加而成；</p>
<p>$$U_{ij}^{l}(t)=w_{ij}O_{j}^{l-1}(t)+H_{ij}^{l}(t)$$</p>
<p>其中$w_{ij}$为权重；</p>
<p>（2）胞体的电位由各个突触的电位累积而成；</p>
<p>$$U_{i}^{l}(t)=\sum_{j}{U_{ij}^{l}(t)}·[1-O_{i}^{l}(t)]$$</p>
<p>（3）神经元是否产生脉冲，由电位与阈值经过Heaviside阶跃函数$u(·)$得出，</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>其中$u_{th}$为阈电位；</p>
<p>（4）各个突触内的历史由突触电位与胞体是否发射脉冲共同作用而成，</p>
<p>$$H_{ij}^{l}(t)=\tau U_{ij}^{l}(t-1)[1-O_{i}^{l}(t-1)]$$</p>
<p>其中$\tau $为时间常数。</p>
<p><img alt="SRM0神经元计算示意图" src="./assets/1-3.png" /></p>
<p>整个模型可用python模拟如下：</p>
<pre><code class="language-python">import torch

class Heaviside(torch.autograd.Function): 
    @staticmethod
    def forward(ctx, i):
        ctx.save_for_backward(i)
        return i.gt(0).float()

    @staticmethod
    def backward(ctx, g_o):
        i = ctx.saved_tensors
        g_i = g_o.clone() 
        temp = abs(i) &lt; 0.5
        return g_i * temp.float(), None

class SRM0(torch.nn.Module):
    def __init__(self, input_shape: int, output_shape: int, max_weight: float, threshold: float, tau: float, weights: torch.tensor = None):
        super().__init__()
        self.input_shape = input_shape
        self.output_shape = output_shape
        self.max_weight = max_weight
        self.threshold = threshold
        self.sigma = torch.ones(self.input_shape, 1)
        self.tau = tau
        if weights is None:
            self.weights = torch.rand(self.output_shape, self.input_shape) * max_weight
        else:
            self.weights = weights
        self.history = torch.zeros(self.output_shape, self.input_shape)

    def forward(self, x):
        x = self.weights * x + self.history * self.tau
        u = x @ self.sigma
        u = u.view(self.output_shape)
        o = Heaviside.apply(u - self.threshold)
        self.history = (x * self.tau) * (1 - torch.repeat_interleave(o.view(self.output_shape, 1), self.input_shape, dim = 1))
        return o

if __name__ == &quot;__main__&quot;:
    values = [5, 2, 8, 4, 0, 3]
    prec = 40
    rc = rate_coding(values, prec)
    srm0 = SRM0(6, 4, 8, 10, 0.5)

    for i in range(prec):
        input_spikes = next(rc)
        output_spikes = srm0(input_spikes)
        print(output_spikes)
</code></pre>
<h3 id="24-leaky-integrate-and-analog-fireliaf">2.4 Leaky Integrate and Analog Fire（LIAF）模型</h3>
<p>LIF模型的输入与输出均为脉冲，其在神经元中经历了电压积累与脉冲计算的过程；而LIAF模型的输入与输出均为模拟电位值，其神经元内部和LIF神经元类似，但输出的值为模拟电位$U_{i}^{l}(t)$。</p>
<p>整个LIAF模型使用公式描述如下：$^{[7]}$</p>
<p>（1）神经元胞体电位，由突触传来的电位与历史电位相加而成；</p>
<p>$$U_{i}^{l}(t)=\sum_{j}{w_{ij}X_{j}^{l-1}(t)}+H_{i}^{l}(t)$$</p>
<p>其中$w_{ij}$为权重；</p>
<p>（2）神经元是否产生脉冲，由电位与阈值经过Heaviside阶跃函数$u(·)$得出，但不以脉冲作为输出，脉冲仅用于计算历史电位，</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>其中$u_{th}$为阈电位；</p>
<p>（3）神经元历史电位，由当前电位与是否产生脉冲得出，</p>
<p>$$H_{i}^{l}(t)=\alpha [u_{reset}O_{i}^{l}(t-1)+U_{i}^{l}(t-1)[1-O_{i}^{l}(t-1)]]+\beta $$</p>
<p>其中$\alpha $，$\beta $为参数，$u_{reset}$为重置电位；</p>
<p>（4）神经元的输出取决于神经元当前的电位，</p>
<p>$$X_{i}^{l}(t)=f[U_{i}^{l}(t),u_{th}]$$</p>
<p>其中$f(·)$为动作函数（但不能是阶跃函数$u(·)$，否则会降级为LIF）。</p>
<p><img alt="LIAF神经元计算示意图" src="./assets/1-4.png" /></p>
<p>整个模型可用python模拟如下：</p>
<pre><code class="language-python">import torch

class Heaviside(torch.autograd.Function): 
    @staticmethod
    def forward(ctx, i):
        ctx.save_for_backward(i)
        return i.gt(0).float()

    @staticmethod
    def backward(ctx, g_o):
        i = ctx.saved_tensors
        g_i = g_o.clone() 
        temp = abs(i) &lt; 0.5
        return g_i * temp.float(), None

class LIAF(torch.nn.Module):
    def __init__(self, input_shape: int, output_shape: int, max_weight: float, threshold: float, alpha: float, beta: float, act_fun: torch.nn.Module = torch.nn.ReLU(), weights: torch.tensor = None):
        super().__init__()
        self.input_shape = input_shape
        self.output_shape = output_shape
        self.max_weight = max_weight
        self.threshold = threshold
        self.alpha = alpha
        self.beta = beta
        self.act_fun = act_fun
        if weights is None:
            self.weights = torch.rand(self.output_shape, self.input_shape) * max_weight
        else:
            self.weights = weights
        self.history = torch.zeros(self.output_shape)

    def forward(self, x):
        x = x.view(self.input_shape, 1)
        x = self.weights @ x
        x = x.view(self.output_shape)
        x = x + self.history
        o = Heaviside.apply(x - self.threshold)
        self.history = self.alpha * (x * (1 - o)) + self.beta
        x = self.act_fun(x - self.threshold)
        return x

if __name__ == &quot;__main__&quot;:
    values = [5, 2, 8, 4, 0, 3]
    prec = 40
    rc = rate_coding(values, prec)
    liaf = LIAF(6, 4, 8, 12, 0.5, 0.5)

    for i in range(prec):
        input_spikes = next(rc)
        output_spikes = liaf(input_spikes)
        print(output_spikes)
</code></pre>
<h2 id="3">3 脉冲神经网络的训练</h2>
<p>脉冲神经网络的参数要经过训练，才能完美地完成我们所给予的任务。脉冲神经网络的训练方式多种多样。此处采取Wu等人（2018）的分类方式，将脉冲神经网络的训练分为如下三类：$^{[10]}$</p>
<h3 id="31">3.1 无监督学习</h3>
<p>无监督学习旨在通过观察每个神经元自己的输入与输出来自动调整每个神经元的权重，以对不同的输入模式做不同的响应。在这之中，最典型的无监督学习方式就是STDP。</p>
<h4 id="311-stdp">3.1.1 脉冲时序依赖可塑性（STDP）</h4>
<p>脉冲时序依赖可塑性（Spike-timing Dependent Plasticity, STDP）可以用来训练脉冲神经网络的神经元。作为一个时许非对称形式的Hebb学习法则，其依赖突触前和突触后神经元脉冲之间的紧密时间相关性来进行训练。$^{[8],[9]}$</p>
<p>假设编号为$i$的神经元第$j$个突触的输入脉冲序列为$\vec{t}_{j}=\{t|O_{j}^{l-1}(t)=1\}$，输出脉冲序列为$\vec{t}_{i}=\{t|O_{i}^{l}(t)=1\}$，则对于该神经元的第$j$个突触，其权重变化值为</p>
<p>$$\Delta w_{ij}=\sum_{t_{j}∈\vec{t}_{j}}{\sum_{t_{i}∈\vec{t}_{i}}W(t_{i}-t_{j})}$$</p>
<p>其中STDP函数$W(x)$一般定义如下：</p>
<p>$$
W(x)=
\left\{
\begin{aligned}
A_{+}e^{-\frac{x}{\tau _{+}}},x&gt; 0 \\\\
0,x=0 \\\\
-A_{-}e^{\frac{x}{\tau _{-}}},x&lt; 0
\end{aligned}
\right.
$$</p>
<p>其中$A_{+}$、$A_{-}$、$\tau _{+}$、$\tau _{-}$均为需设定的参数。</p>
<p><img alt="脉冲时序依赖可塑性（STDP）示意图" src="./assets/1-5.jpg" /></p>
<p>STDP可以用python模拟如下：</p>
<pre><code class="language-python">import math
import torch

def STDP(input_shape: int, output_shape: int, time_steps: int, input_spike_train: torch.tensor, output_spike_train: torch.tensor, weight_matrix: torch.tensor, max_weight: float, a_pos: float, a_neg: float, tau_pos: float, tau_neg: float):
    &quot;&quot;&quot;
    通过STDP更新权重
    @params:
        input_shape: int 输入长度j（该层每个神经元突触长度）
        output_shape: int 输出长度i（该层神经元长度）
        time_steps: int 总时间步长t
        input_spike_train: torch.tensor 输入脉冲序列，一个形状为j×t的矩阵，每个元素0代表无脉冲，1代表有脉冲
        output_spike_train: torch.tensor 输出脉冲序列，一个形状为i×t的矩阵，每个元素0代表无脉冲，1代表有脉冲
        weight_matrix: torch.tensor 权重矩阵，一个形状为i×j的矩阵
        max_weight: float 最大权重
        a_pos: 参数A+
        a_neg: 参数A-
        tau_pos: 参数τ+
        tau_neg: 参数τ-
    @return:
        torch.tensor 更新后的权重矩阵
    &quot;&quot;&quot;
    for i in range(output_shape):
        for j in range(input_shape):
            delta_w = 0.0
            for tj in range(time_steps):
                if input_spike_train[j, tj]:
                    for ti in range(time_steps):
                        if output_spike_train[i, ti]:
                            delta_t = ti - tj
                            if delta_t == 0:
                                delta_w += 0
                            elif delta_t &gt; 0:
                                delta_w += a_pos * math.exp(-delta_t / tau_pos)
                            elif delta_t &lt; 0:
                                delta_w += -a_neg * math.exp(delta_t / tau_neg)
            weight_matrix[i, j] += delta_w
    return weight_matrix
</code></pre>
<h3 id="32">3.2 间接监督学习</h3>
<p>间接监督学习并非直接训练脉冲神经网络，而是通过其它方式训练网络，再将训练好的网络或参数置入脉冲神经网络之中。其中最典型的方法即为ANN转SNN。</p>
<h4 id="321-annsnn">3.2.1 ANN转SNN</h4>
<p>Rueckauer等人（2017）的工作表明，脉冲神经网络中的IF神经元是ReLU激活函数在时间上的无偏估计。$^{[11]}$</p>
<p><img alt="IF神经元脉冲发放率与输入的比值，与ReLU函数进行比较" src="./assets/1-6.png" /></p>
<p>由于脉冲发放率的取值范围为$[0,1]$，因此在ANN转SNN时，还要对各个参数进行归一化。假设模拟神经网络中输入张量的最大值为$\lambda _{pre}$，输出张量的最大值为$\lambda $，则归一化后的权重为</p>
<p>$$\hat{W}=W\frac{\lambda _{pre}}{\lambda }$$</p>
<p>$$\hat{b}=\frac{b}{\lambda }$$</p>
<p>使用<a href="https://github.com/fangwei123456/spikingjelly">spikingjelly</a>完成从ANN到SNN的转换：</p>
<pre><code class="language-python">import torch
from torch import nn

class ANN(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1),
            nn.BatchNorm2d(32, eps=1e-3),
            nn.ReLU(),
            nn.AvgPool2d(2, 2),

            nn.Conv2d(32, 32, 3, 1),
            nn.BatchNorm2d(32, eps=1e-3),
            nn.ReLU(),
            nn.AvgPool2d(2, 2),

            nn.Conv2d(32, 32, 3, 1),
            nn.BatchNorm2d(32, eps=1e-3),
            nn.ReLU(),
            nn.AvgPool2d(2, 2),

            nn.Flatten(),
            nn.Linear(32, 10),
            nn.ReLU()
        )

    def forward(self,x):
        x = self.network(x)
        return x

model = ANN()
</code></pre>
<p>省略训练过程。</p>
<pre><code class="language-python">model_converter = ann2snn.Converter(mode='max', dataloader=train_data_loader)
snn_model = model_converter(model)
</code></pre>
<p>可以得到最终转换而成的脉冲神经网络模型：</p>
<pre><code class="language-python">ANN(
  (network): Module(
    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (12): Flatten(start_dim=1, end_dim=-1)
    (13): Linear(in_features=32, out_features=10, bias=True)
    (15): Softmax(dim=1)
  )
  (snn tailor): Module(
    (0): Module(
      (0): VoltageScaler(0.240048)
      (1): IFNode(
        v_threshold=1.0, v_reset=None, detach_reset=False, step_mode=s, backend=torch
        (surrogate_function): Sigmoid(alpha=4.0, spiking=True)
      )
      (2): VoltageScaler(4.165831)
    )
    (1): Module(
      (0): VoltageScaler(0.307485)
      (1): IFNode(
        v_threshold=1.0, v_reset=None, detach_reset=False, step_mode=s, backend=torch
        (surrogate_function): Sigmoid(alpha=4.0, spiking=True)
      )
      (2): VoltageScaler(3.252196)
    )
    (2): Module(
      (0): VoltageScaler(0.141659)
      (1): IFNode(
        v_threshold=1.0, v_reset=None, detach_reset=False, step_mode=s, backend=torch
        (surrogate_function): Sigmoid(alpha=4.0, spiking=True)
      )
      (2): VoltageScaler(7.059210)
    )
    (3): Module(
      (0): VoltageScaler(0.060785)
      (1): IFNode(
        v_threshold=1.0, v_reset=None, detach_reset=False, step_mode=s, backend=torch
        (surrogate_function): Sigmoid(alpha=4.0, spiking=True)
      )
      (2): VoltageScaler(16.451399)
    )
  )
)
</code></pre>
<p>由于通过ANN转SNN方法可以将对于脉冲神经网络的训练转为对于模拟神经网络的训练，此处不再赘述训练方式。</p>
<h3 id="33">3.3 直接监督学习</h3>
<h4 id="331-stbp">3.3.1 时间-空间反向传播（STBP）</h4>
<p>时间-空间反向传播（Spatio-Temporal Backpropagation, STBP）由Wu等人（2018）提出，利用LIF神经元中关于电位、脉冲之间的内在关系，将传统的反向传播应用在基于时间-空间结构的脉冲神经网络中。$^{[10]}$</p>
<p>回顾描述LIF神经元的数学公式：</p>
<p>$$U_{i}^{l}(t)=\sum_{j}{w_{ij}O_{j}^{l-1}(t)}+b_{i}+H_{i}^{l}(t)$$</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>$$H_{i}^{l}(t)=\tau U_{i}^{l}(t-1)[1-O_{i}^{l}(t-1)]$$</p>
<p>根据链式求导法则，可以推得：</p>
<p>$$\frac{\partial U_{i}^{l}(t)}{\partial O_{j}^{l-1}(t)}=w_{ij}$$</p>
<p>$$\frac{\partial O_{i}^{l}(t)}{\partial U_{i}^{l}(t)}=\frac{\partial u}{\partial U_{i}^{l}(t)}$$</p>
<p>$$\frac{\partial U_{i}^{l}(t)}{\partial U_{i}^{l}(t-1)}=\tau [1-O_{i}^{l}(t-1)]$$</p>
<p>$$\frac{\partial O_{i}^{l}(t)}{\partial O_{i}^{l}(t-1)}=\frac{\partial O_{i}^{l}(t)}{\partial U_{i}^{l}(t)}\frac{\partial U_{i}^{l}(t)}{\partial O_{i}^{l}(t-1)}=-\tau U_{i}^{l}(t-1)\frac{\partial u}{\partial U_{i}^{l}(t)}$$</p>
<p><img alt="时间-空间反向传播（STBP）示意图" src="./assets/1-7.png" /></p>
<p>设损失为均方差损失：</p>
<p>$$L=\frac{1}{2S}\sum_{s=1}^{S}{||y_{s}-\frac{1}{T}\sum_{t=1}^{T}{O_{s}^{N}(t)}||}_{2}^{2}$$</p>
<p>则：</p>
<p>（1）对于最后一层$l=N$，其只需要考虑在时间维度的求导：</p>
<p>对于最后一个时间刻$t=T$：</p>
<p>$$\delta _{i}^{N}(T)=\frac{\partial L}{\partial O_{i}^{N}(T)}=-\frac{1}{TS}[y_{i}-\frac{1}{T}\sum_{t=1}^{T}{O_{i}^{N}(t)}]$$</p>
<p>$$\frac{\partial L}{\partial U_{i}^{N}(T)}=\delta _{i}^{N}(T)\frac{\partial O_{i}^{N}(T)}{\partial U_{i}^{N}(T)}=\delta _{i}^{N}(T)\frac{\partial u}{\partial U_{i}^{N}(T)}$$</p>
<p>对于前面的时间刻$t&lt; T$：</p>
<p>$$\delta _{i}^{N}(t)=\frac{\partial L}{\partial O_{i}^{N}(t)}=\frac{\partial L}{\partial O_{i}^{N}(t+1)}\frac{\partial O_{i}^{N}(t+1)}{\partial O_{i}^{N}(t)}+\delta _{i}^{N}(T)=-\tau U_{i}^{N}(t)\delta _{i}^{N}(t+1)\frac{\partial u}{\partial U_{i}^{N}(t+1)}+\delta _{i}^{N}(T)$$</p>
<p>$$\frac{\partial L}{\partial U_{i}^{N}(t)}=\frac{\partial L}{\partial U_{i}^{N}(t+1)}\frac{\partial U_{i}^{l}(t+1)}{\partial U_{i}^{l}(t)}=\delta _{i}^{N}(t+1)\tau [1-O_{i}^{N}(t)]\frac{\partial u}{\partial U_{i}^{N}(t+1)}$$</p>
<p>（2）对于前面的层$l&lt; N$，其在考虑时间维度求导的基础上，还要考虑空间维度求导：</p>
<p>对于最后一个时间刻$t=T$：</p>
<p>$$\delta _{i}^{l}(T)=\frac{\partial L}{\partial O_{i}^{l}(T)}=\sum_{j}{\delta _{j}^{l+1}(T)\frac{\partial O_{j}^{l+1}(T)}{\partial O_{i}^{l}(T)}}=\sum_{j}{\delta _{j}^{l+1}(T)\frac{\partial u}{\partial U_{j}^{l+1}(T)}w_{ji}}$$</p>
<p>$$\frac{\partial L}{\partial U_{i}^{l}(T)}=\delta _{i}^{l}(T)\frac{\partial O_{i}^{l}(T)}{\partial U_{i}^{l}(T)}=\delta _{i}^{l}(T)\frac{\partial u}{\partial U_{i}^{l}(T)}$$</p>
<p>对于前面的时间刻$t&lt; T$：</p>
<p>$$\delta _{i}^{l}(t)=\frac{\partial L}{\partial O_{i}^{l}(t)}=\sum_{j}{\delta _{j}^{l+1}(t)\frac{\partial O_{j}^{l+1}(t)}{\partial O_{i}^{l}(t)}}+\frac{\partial L}{\partial O_{i}^{l}(t+1)}\frac{\partial O_{i}^{l}(t+1)}{\partial O_{i}^{l}(t)}=\sum_{j}{\delta _{j}^{l+1}(t)\frac{\partial u}{\partial U_{j}^{l+1}(t)}w_{ji}}-\tau U_{i}^{l}(t)\delta _{i}^{l}(t+1)\frac{\partial u}{\partial U_{i}^{l}(t+1)}$$</p>
<p>$$\frac{\partial L}{\partial U_{i}^{l}(t)}=\delta _{i}^{l}(t)\frac{\partial O_{i}^{l}(t)}{\partial U_{i}^{l}(t)}+\delta _{i}^{l}(t+1)\frac{\partial O_{i}^{l}(t+1)}{\partial U_{i}^{l}(t)}=\delta _{i}^{l}(t)\frac{\partial u}{\partial U_{i}^{l}(t)}+\delta _{i}^{l}(t+1)\tau [1-O_{i}^{l}(t)]$$</p>
<p>随后，便可根据$\frac{\partial L}{\partial O_{i}^{l}(t)}$和$\frac{\partial L}{\partial U_{i}^{l}(t)}$计算$\frac{\partial L}{\partial b^{l}}$与$\frac{\partial L}{\partial w^{l}}$：</p>
<p>$$\frac{\partial L}{\partial b_{i}^{l}}=\sum_{t=1}^{T}{\frac{\partial L}{\partial U_{i}^{l}(t)}\frac{\partial U_{i}^{l}(t)}{\partial b_{i}^{l}}}=\sum_{t=1}^{T}{\frac{\partial L}{\partial U_{i}^{l}(t)}}$$</p>
<p>$$\frac{\partial L}{\partial w_{ij}^{l}}=\sum_{t=1}^{T}{\frac{\partial L}{\partial U_{i}^{l}(t)}\frac{\partial U_{i}^{l}(t)}{\partial w_{ij}^{l}}}=\sum_{t=1}^{T}{\frac{\partial L}{\partial U_{i}^{l}(t)}O_{j}^{l-1}(t)}$$</p>
<p>由此便可更新整个脉冲神经网络的参数。</p>
<p>对于不可导的Heaviside阶跃函数$u(·)$，使用它的导数近似。STBP的原文中给出了4种Heaviside阶跃函数的导数近似：</p>
<p>（1）矩形函数：</p>
<p>$$\frac{\partial u}{\partial x}=\frac{1}{a}sign(|x|&lt; \frac{a}{2})$$</p>
<p>（2）多项式函数：</p>
<p>$$\frac{\partial u}{\partial x}=(\frac{\sqrt{a}}{2}-\frac{a}{4}|x|)sign(\frac{2}{\sqrt{a}}-|x|)$$</p>
<p>（3）sigmoid函数导数：</p>
<p>$$\frac{\partial u}{\partial x}=\frac{1}{a}\frac{e^{-\frac{x}{a}}}{(1+e^{-\frac{x}{a}})^{2}}$$</p>
<p>（4）高斯分布函数：</p>
<p>$$\frac{\partial u}{\partial x}=\frac{1}{\sqrt{2\pi a}}e^{-\frac{x^{2}}{2a}}$$</p>
<p>由于此算法可借助pytorch中的自动求导实现，因此此处不再给出具体实现方式。可以参考代码仓库<a href="https://github.com/yjwu17/STBP-for-training-SpikingNN">https://github.com/yjwu17/STBP-for-training-SpikingNN</a>。</p>
<h4 id="332-bptt">3.3.2 沿时间反向传播（BPTT）</h4>
<p>沿时间反向传播（Backpropagation Through Time, BPTT）最早由Paul提出（1990），用于训练循环神经网络。与STBP类似，BPTT利用循环神经网络的时间特性，在空间与时间两个维度进行反向传播。$^{[12]}$在RNN上适用的BPTT在脉冲神经网络上同样使用。以下以BPTT在LIAF中的应用举例：$^{[7]}$</p>
<p>回顾描述LIAF神经元的数学公式：</p>
<p>$$U_{i}^{l}(t)=\sum_{j}{w_{ij}X_{j}^{l-1}(t)}+H_{i}^{l}(t)$$</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>$$H_{i}^{l}(t)=\alpha [u_{reset}O_{i}^{l}(t-1)+U_{i}^{l}(t-1)[1-O_{i}^{l}(t-1)]]+\beta $$</p>
<p>$$X_{i}^{l}(t)=f[U_{i}^{l}(t),u_{th}]$$</p>
<p>根据链式求导法则，可以推得：</p>
<p>$$\frac{\partial U_{i}^{l}(t)}{\partial U_{i}^{l}(t-1)}=\frac{\partial U_{i}^{l}(t)}{\partial H_{i}^{l}(t)}\frac{\partial H_{i}^{l}(t)}{\partial U_{i}^{l}(t-1)}=\alpha [u_{reset}-U_{i}^{l}(t-1)]\frac{\partial u}{\partial U_{i}^{l}(t-1)}+\alpha [1-u[U_{i}^{l}(t-1)]]$$</p>
<p>$$\frac{\partial U_{i}^{l}(t)}{\partial U_{j}^{l-1}(t)}=\frac{\partial U_{i}^{l}(t)}{\partial X_{j}^{l-1}(t)}\frac{\partial X_{j}^{l-1}(t)}{\partial U_{j}^{l-1}(t)}=w_{ij}\frac{\partial f}{\partial U_{j}^{l-1}(t)}$$</p>
<p>通过这种方式，可以进行类似于STBP的反向传播，将损失传播至整个网络与整个时间步之中，进而实现参数的更新。</p>
<p>$$\frac{\partial L}{\partial w_{ij}^{l}}=\frac{\partial L}{\partial U_{i}^{l}(t)}\frac{\partial U_{i}^{l}(t)}{\partial w_{ij}^{l}}=\frac{\partial L}{\partial U_{i}^{l}(t)}X_{j}^{l-1}(t)$$</p>
<p>对于不可导的Heaviside阶跃函数$u(·)$，使用它的导数近似：</p>
<p>$$
\frac{\partial u}{\partial x}=
\left\{
\begin{aligned}
1,|x|&lt; \mu  \\\\
0,otherwise
\end{aligned}
\right.
$$</p>
<p>其中$\mu $为微小正数。</p>
<h2 id="4">4 脉冲神经网络的硬件部署</h2>
<p>作为第三代神经网络，脉冲神经网络的计算不同于传统模拟神经网络中对模拟数值的线性运算。脉冲神经网络中的计算涉及到各个神经元的电位累积、激发、重置与泄露过程，因此基于传统模拟计算实现的脉冲神经网络皆为模拟的神经元。如何将脉冲神经网络的计算过程在电路上实现出来，一直是备受关注的研究课题。本节所讨论的即为脉冲神经网络在硬件上的部署。</p>
<h3 id="41-iir">4.1 脉冲神经网络以IIR的形式部署</h3>
<p>Fang等人（2020）在FPGA上以无限冲激响应（IIR）滤波器的形式将脉冲神经网络部署在FPGA上，并取得了不错的成果。$^{[13]}$他们将SNN中的SRM0神经元：</p>
<p>（1）胞体内的电位变化由胞体的历史电位，输入导致的电位变化与重置导致的电位变化叠加而成</p>
<p>$$U_{i}^{l}(t)=\lambda U_{i}^{l}(t-1)+I_{i}^{l}(t)-\theta _{r}R_{i}^{l}(t)$$</p>
<p>（2）其中输入导致的电位变化由各个突触的反应函数叠加而成</p>
<p>$$I_{i}^{l}(t)=\sum_{j}{w_{ij}^{l}U_{ij}^{l}(t)}$$</p>
<p>（3）将重置看作一个反向的电位变化</p>
<p>$$R_{i}^{l}(t)=\theta R_{i}^{l}(t-1)+O_{i}^{l}(t)$$</p>
<p>（4）各个突触的反应函数</p>
<p>$$U_{ij}^{l}(t)=\sum_{p=1}^{P}{\alpha _{j,p}^{l}U_{ij}^{l}(t-p)}+\sum_{q=0}^{Q}{\beta _{j,q}^{l}O_{j}^{l-1}(t-q)}$$</p>
<p>（5）该神经元是否产生脉冲由胞体电位经过Heaviside阶跃函数$u(·)$决定</p>
<p>$$O_{i}^{l}(t)=u[U_{i}^{l}(t)-u_{th}]$$</p>
<p>其中，涉及到时间序列的方程，如（1）（3）（4），都可以将其看作一个IIR滤波器来进行计算。由此可以得出使用IIR滤波器构建的SRM0神经元如下图所示：</p>
<p><img alt="使用IIR滤波器构造SRM0神经元（算法实现）" src="./assets/1-8.png" /></p>
<p><img alt="使用IIR滤波器构造SRM0神经元（硬件实现）" src="./assets/1-9.png" /></p>
<p>借此，可以构造基于IIR滤波器的脉冲神经网络，进而实现脉冲神经网络的硬件级加速。</p>
<h3 id="42">4.2 敬请期待</h3>
<h2 id="_2">参考文献</h2>
<p>[1] Smith J E. Space-time computing with temporal neural networks[J]. Synthesis Lectures on Computer Architecture, 2017, 12(2): i-215.</p>
<p>[2] Fidjeland A K, Roesch E B, Shanahan M P, et al. NeMo: a platform for neural modelling of spiking neurons using GPUs[C]//2009 20th IEEE international conference on application-specific systems, architectures and processors. IEEE, 2009: 137-144.</p>
<p>[3] Lazar A A. Time encoding with an integrate-and-fire neuron with a refractory period[J]. Neurocomputing, 2004, 58: 53-58.</p>
<p>[4] Hodgkin A L, Huxley A F. A quantitative description of membrane current and its application to conduction and excitation in nerve[J]. The Journal of physiology, 1952, 117(4): 500.</p>
<p>[5] Smith J E. Efficient digital neurons for large scale cortical architectures[J]. ACM SIGARCH Computer Architecture News, 2014, 42(3): 229-240.</p>
<p>[6] Gerstner W, Kistler W M. Spiking neuron models: Single neurons, populations, plasticity[M]. Cambridge university press, 2002.</p>
<p>[7] Wu Z, Zhang H, Lin Y, et al. Liaf-net: Leaky integrate and analog fire network for lightweight and efficient spatiotemporal information processing[J]. IEEE Transactions on Neural Networks and Learning Systems, 2021, 33(11): 6249-6262.</p>
<p>[8] Dan Y, Poo M. Spike timing-dependent plasticity of neural circuits[J]. Neuron, 2004, 44(1): 23-30.</p>
<p>[9] Jesper Sjöström, Wulfram Gerstner. Spike-timing dependent plasticity[J]. Scholarpedia, 5(2):1362.</p>
<p>[10] Wu Y, Deng L, Li G, et al. Spatio-temporal backpropagation for training high-performance spiking neural networks[J]. Frontiers in neuroscience, 2018, 12: 331.</p>
<p>[11] Rueckauer B, Lungu I A, Hu Y, et al. Conversion of continuous-valued deep networks to efficient event-driven networks for image classification[J]. Frontiers in neuroscience, 2017, 11: 682.</p>
<p>[12] Werbos P J. Backpropagation through time: what it does and how to do it[J]. Proceedings of the IEEE, 1990, 78(10): 1550-1560.</p>
<p>[13] Fang H, Mei Z, Shrestha A, et al. Encoding, model, and architecture: Systematic optimization for spiking neural network in FPGAs[C]//Proceedings of the 39th International Conference on Computer-Aided Design. 2020: 1-9.</p>
        </div>
    </div>

    <div id="footer" style="padding: 2rem 0;">
        <div class="mdui-text-center mdui-text-color-grey">
            @AmperiaWang
            <span id="footer-year"></span>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/mdui@1.0.1/dist/js/mdui.min.js"
        integrity="sha384-gCMZcshYKOGRX9r6wbDrvF+TcCCswSHFucUzUPwka+Gr+uHgjlYvkABr95TCOz3A"
        crossorigin="anonymous"></script>
    <script src="https://cdn.bootcdn.net/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>
        function comingSoon() {
            mdui.snackbar("敬请期待");
        }

        function formatContent(node) {
            let len = node.childNodes.length;
            if (!len) {
                return;
            }
            for (let idx = 0; idx < len; idx++) {
                let el = node.childNodes[idx];
                let elTag = el.nodeName.toLowerCase();
                if (elTag == "img") {
                    if (node.className == "mdui-text-center") {
                        break;
                    }
                    node.setAttribute("class", "mdui-text-center");
                    let imageDescription = document.createElement("div");
                    imageDescription.setAttribute("class", "description mdui-text-color-grey mdui-typo-caption");
                    imageDescription.innerHTML = "图<span class='image-index'></span>&nbsp;&nbsp;" + el.alt;
                    el.outerHTML = el.outerHTML + imageDescription.outerHTML;
                    len++;
                    idx++;
                }
                if (elTag == "table") {
                    el.setAttribute("class", "mdui-table");
                }
                formatContent(el);
            }
        }

        var inst = new mdui.Tab("#appbar-tab");
        MathJax = {
            tex: {
                inlineMath: [["$", "$"]]
            }
        };

        document.onreadystatechange = function (e) {
            let footerYear = document.getElementById("footer-year");
            footerYear.innerHTML = (new Date()).getFullYear();

            let content = document.getElementById("content");

            formatContent(content);

            let indices = document.getElementsByClassName("image-index");
            for (let idx = 0; idx < indices.length; idx++) {
                indices[idx].innerHTML = (idx + 1);
            }

            mdui.mutation();

            hljs.highlightAll();
        }
    </script>
    <script id="MathJax-script" async src="https://cdn.bootcss.com/mathjax/3.0.5/es5/tex-mml-chtml.js"></script>
</body>

</html>